{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blstm pytorch final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qM-CHtj3XR4"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors\n",
        "import spacy\n",
        "\n",
        "\n",
        "import time\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dex-JC63zzf"
      },
      "source": [
        "def read_dataset(corpus, fields):\n",
        "    with open(corpus, encoding='utf-8') as corpus:\n",
        "        examples = []\n",
        "        words = []\n",
        "        pos_tags = []\n",
        "        for line in corpus:\n",
        "            if line[0] == '#': \n",
        "                continue            \n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                examples.append(torchtext.data.Example.fromlist([words, pos_tags], fields))\n",
        "                words = []\n",
        "                pos_tags = []\n",
        "            else:\n",
        "                columns = line.split('\\t')\n",
        "                if '.' in columns[0] or '-' in columns[0]:\n",
        "                    continue\n",
        "                words.append(columns[1])\n",
        "                pos_tags.append(columns[3])\n",
        "        return torchtext.data.Dataset(examples, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfEQOIqo6AUQ"
      },
      "source": [
        "class BiLSTMPOSTagger(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim, \n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                            hidden_dim, \n",
        "                            num_layers = n_layers, \n",
        "                            bidirectional = bidirectional,\n",
        "                            dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        \n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "                \n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHtYsDlh6W-L"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpYVHgMc6daA"
      },
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) \n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozXA1_FX6oZW"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        text = batch.text\n",
        "        tags = batch.udtags\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text)\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "        loss = criterion(predictions, tags)     \n",
        "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()  \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOGylFyy7Sjy"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ9f3_y27X8I"
      },
      "source": [
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            tags = batch.udtags\n",
        "            predictions = model(text)\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "            loss = criterion(predictions, tags)\n",
        "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFbHlsPJ7l20"
      },
      "source": [
        "def build_model(dataset, embedding, text, tags, pretrained=None):\n",
        "    \n",
        "    text.build_vocab(dataset, \n",
        "                 min_freq = 2,\n",
        "                 vectors = embedding,\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "    tags.build_vocab(dataset)\n",
        "\n",
        "    model = BiLSTMPOSTagger(len(text.vocab), \n",
        "                        300, \n",
        "                        100, \n",
        "                        len(tags.vocab), \n",
        "                        2, \n",
        "                        bidirectional=True, \n",
        "                        dropout=0.25, \n",
        "                        pad_idx=text.vocab.stoi[text.pad_token])\n",
        "    model.embedding.weight.data.copy_(text.vocab.vectors)\n",
        "    model.embedding.weight.data[text.vocab.stoi[text.pad_token]] = torch.zeros(300)\n",
        "\n",
        "    if pretrained:\n",
        "        weights = torch.load(pretrained)\n",
        "        del weights['embedding.weight']\n",
        "        model.load_state_dict(weights, strict=False)\n",
        "    else:\n",
        "        model.apply(init_weights)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1sdn94TCq65"
      },
      "source": [
        "def train_model(model, name, data_train, data_dev, optimizer, criterion, batch_size=128, n_epochs=10):\n",
        "    train_iterator, valid_iterator = data.BucketIterator.splits((data_train, data_dev), \n",
        "                                                                batch_size = batch_size, \n",
        "                                                                sort=False)\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "        \n",
        "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
        "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
        "        \n",
        "        end_time = time.time()\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), name + '.pt')\n",
        "        \n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x2GmwQT7-Me"
      },
      "source": [
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0LP-vx4DtP3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJZ5TB2KDvj0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5eF1M7qGXUn"
      },
      "source": [
        "!gunzip /content/drive/My\\ Drive/diploma/cc.uk.300.vec.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km_H-qMfd5hQ"
      },
      "source": [
        "SEED = 111\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxEJKet2DueM"
      },
      "source": [
        "ru_vec_emb = '/content/drive/My Drive/diploma/cc.ru.300.vec'\n",
        "uk_vec_emb = '/content/drive/My Drive/diploma/cc.uk.300.vec'\n",
        "uk_vec = Vectors(name=uk_vec_emb)\n",
        "ru_vec = Vectors(name=ru_vec_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypbhXFR7DtLq"
      },
      "source": [
        "TEXT = data.Field(lower = True)\n",
        "UD_TAGS = data.Field(unk_token = None)\n",
        "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HAnowEXDtFu"
      },
      "source": [
        "uk_train = read_dataset('/content/drive/My Drive/diploma/uk_iu-ud-train.conllu', fields)\n",
        "uk_dev = read_dataset('/content/drive/My Drive/diploma/uk_iu-ud-dev.conllu.txt', fields)\n",
        "uk_test = read_dataset('/content/drive/My Drive/diploma/uk_iu-ud-test.conllu.txt', fields)\n",
        "\n",
        "ru_train = read_dataset('/content/drive/My Drive/diploma/ru_syntagrus-ud-train.conllu.txt', fields)\n",
        "ru_dev = read_dataset('/content/drive/My Drive/diploma/ru_syntagrus-ud-dev.conllu.txt', fields)\n",
        "ru_test = read_dataset('/content/drive/My Drive/diploma/ru_syntagrus-ud-test.conllu.txt', fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC78zcHCSVud"
      },
      "source": [
        "uk_train_low, _ = torchtext.data.Dataset.split(uk_train, 0.25, random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryJGXBx7eDKY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "451045d3-bfa5-4a32-b749-e839bd98526b"
      },
      "source": [
        "len(uk_train_low)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhNRaJR0boiy"
      },
      "source": [
        "## Train on ukrainian dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoeSDJAeUQnW"
      },
      "source": [
        "uk_model = build_model(uk_train, uk_vec, TEXT, UD_TAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKNErJVGU983"
      },
      "source": [
        "optimizer_uk = optim.Adam(uk_model.parameters())\n",
        "\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "\n",
        "criterion_uk = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EZ9aQDQU43u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "57783133-8a16-4ac4-ac7d-a18caf49edb9"
      },
      "source": [
        "train_model(uk_model, \"ukrainian_full\", uk_train, uk_dev, optimizer_uk, criterion_uk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 5s\n",
            "\tTrain Loss: 2.125 | Train Acc: 33.06%\n",
            "\t Val. Loss: 1.497 |  Val. Acc: 53.66%\n",
            "Epoch: 02 | Epoch Time: 0m 51s\n",
            "\tTrain Loss: 1.151 | Train Acc: 63.33%\n",
            "\t Val. Loss: 0.778 |  Val. Acc: 73.96%\n",
            "Epoch: 03 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.660 | Train Acc: 78.47%\n",
            "\t Val. Loss: 0.557 |  Val. Acc: 81.19%\n",
            "Epoch: 04 | Epoch Time: 0m 46s\n",
            "\tTrain Loss: 0.462 | Train Acc: 85.38%\n",
            "\t Val. Loss: 0.481 |  Val. Acc: 83.90%\n",
            "Epoch: 05 | Epoch Time: 0m 56s\n",
            "\tTrain Loss: 0.376 | Train Acc: 88.13%\n",
            "\t Val. Loss: 0.447 |  Val. Acc: 84.87%\n",
            "Epoch: 06 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.332 | Train Acc: 89.31%\n",
            "\t Val. Loss: 0.458 |  Val. Acc: 84.58%\n",
            "Epoch: 07 | Epoch Time: 0m 46s\n",
            "\tTrain Loss: 0.301 | Train Acc: 90.27%\n",
            "\t Val. Loss: 0.440 |  Val. Acc: 85.07%\n",
            "Epoch: 08 | Epoch Time: 0m 47s\n",
            "\tTrain Loss: 0.275 | Train Acc: 91.04%\n",
            "\t Val. Loss: 0.440 |  Val. Acc: 85.28%\n",
            "Epoch: 09 | Epoch Time: 0m 57s\n",
            "\tTrain Loss: 0.251 | Train Acc: 91.83%\n",
            "\t Val. Loss: 0.450 |  Val. Acc: 85.14%\n",
            "Epoch: 10 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.227 | Train Acc: 92.60%\n",
            "\t Val. Loss: 0.462 |  Val. Acc: 84.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vwUWAy2Vh1G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82743b6a-0013-42f2-d19b-d8cb3b91ea49"
      },
      "source": [
        "test_iterator = data.BucketIterator(uk_test, batch_size = 128, sort=False)\n",
        "\n",
        "test_loss, test_acc = evaluate(uk_model, test_iterator, criterion_uk, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.478 |  Test Acc: 83.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw3pHdPLY1a2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q-4rvCpbz_n"
      },
      "source": [
        "## Train on low-resource scenario, Ukrainian dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRCgOzKwb9Dq"
      },
      "source": [
        "uk_model_low = build_model(uk_train_low, uk_vec, TEXT, UD_TAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qnoMDdfcMSP"
      },
      "source": [
        "optimizer_uk_l = optim.Adam(uk_model_low.parameters())\n",
        "\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "\n",
        "criterion_uk_l = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uusJbwoeVhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "2a37f4b5-ca45-4d1e-83fa-85491f4fc0fa"
      },
      "source": [
        "train_model(uk_model_low, \"ukrainian_low\", uk_train_low, uk_dev, optimizer_uk_l, criterion_uk_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 2.531 | Train Acc: 23.07%\n",
            "\t Val. Loss: 2.180 |  Val. Acc: 31.85%\n",
            "Epoch: 02 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 2.172 | Train Acc: 31.25%\n",
            "\t Val. Loss: 1.966 |  Val. Acc: 38.90%\n",
            "Epoch: 03 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.929 | Train Acc: 38.32%\n",
            "\t Val. Loss: 1.690 |  Val. Acc: 45.46%\n",
            "Epoch: 04 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 1.634 | Train Acc: 47.16%\n",
            "\t Val. Loss: 1.395 |  Val. Acc: 57.45%\n",
            "Epoch: 05 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 1.346 | Train Acc: 57.72%\n",
            "\t Val. Loss: 1.171 |  Val. Acc: 62.98%\n",
            "Epoch: 06 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 1.125 | Train Acc: 63.58%\n",
            "\t Val. Loss: 1.015 |  Val. Acc: 66.93%\n",
            "Epoch: 07 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.963 | Train Acc: 68.47%\n",
            "\t Val. Loss: 0.912 |  Val. Acc: 69.98%\n",
            "Epoch: 08 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.850 | Train Acc: 71.91%\n",
            "\t Val. Loss: 0.841 |  Val. Acc: 71.31%\n",
            "Epoch: 09 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 0.768 | Train Acc: 74.57%\n",
            "\t Val. Loss: 0.792 |  Val. Acc: 73.33%\n",
            "Epoch: 10 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 0.699 | Train Acc: 76.94%\n",
            "\t Val. Loss: 0.741 |  Val. Acc: 75.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IumBxDdaeV8_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92cbfdd0-58b7-4dc6-ea36-2f7b2ab9e43a"
      },
      "source": [
        "test_iterator = data.BucketIterator(uk_test, batch_size = 128, sort=False)\n",
        "\n",
        "test_loss, test_acc = evaluate(uk_model_low, test_iterator, criterion_uk_l, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.787 |  Test Acc: 74.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAXq8nQ00qmj"
      },
      "source": [
        "## Train on Russian, test on Ukrainian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxUpmq1TfchC"
      },
      "source": [
        "ru_model = build_model(ru_train, ru_vec, TEXT, UD_TAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJDi0NXM091b"
      },
      "source": [
        "optimizer_ru = optim.Adam(ru_model.parameters())\n",
        "\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "\n",
        "criterion_ru = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucP3L3mB1L6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "7c9dec16-558e-4e50-b53f-1d0498caf5d3"
      },
      "source": [
        "train_model(ru_model, \"russian_full\", ru_train, ru_dev, optimizer_ru, criterion_ru)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 6m 25s\n",
            "\tTrain Loss: 0.643 | Train Acc: 79.24%\n",
            "\t Val. Loss: 0.218 |  Val. Acc: 92.33%\n",
            "Epoch: 02 | Epoch Time: 6m 17s\n",
            "\tTrain Loss: 0.147 | Train Acc: 95.04%\n",
            "\t Val. Loss: 0.184 |  Val. Acc: 93.44%\n",
            "Epoch: 03 | Epoch Time: 6m 24s\n",
            "\tTrain Loss: 0.108 | Train Acc: 96.28%\n",
            "\t Val. Loss: 0.181 |  Val. Acc: 93.64%\n",
            "Epoch: 04 | Epoch Time: 6m 19s\n",
            "\tTrain Loss: 0.087 | Train Acc: 97.01%\n",
            "\t Val. Loss: 0.184 |  Val. Acc: 93.83%\n",
            "Epoch: 05 | Epoch Time: 6m 24s\n",
            "\tTrain Loss: 0.070 | Train Acc: 97.63%\n",
            "\t Val. Loss: 0.193 |  Val. Acc: 93.73%\n",
            "Epoch: 06 | Epoch Time: 6m 19s\n",
            "\tTrain Loss: 0.056 | Train Acc: 98.11%\n",
            "\t Val. Loss: 0.207 |  Val. Acc: 93.76%\n",
            "Epoch: 07 | Epoch Time: 6m 21s\n",
            "\tTrain Loss: 0.044 | Train Acc: 98.52%\n",
            "\t Val. Loss: 0.229 |  Val. Acc: 93.62%\n",
            "Epoch: 08 | Epoch Time: 6m 11s\n",
            "\tTrain Loss: 0.035 | Train Acc: 98.82%\n",
            "\t Val. Loss: 0.253 |  Val. Acc: 93.46%\n",
            "Epoch: 09 | Epoch Time: 6m 12s\n",
            "\tTrain Loss: 0.028 | Train Acc: 99.06%\n",
            "\t Val. Loss: 0.267 |  Val. Acc: 93.45%\n",
            "Epoch: 10 | Epoch Time: 6m 19s\n",
            "\tTrain Loss: 0.023 | Train Acc: 99.23%\n",
            "\t Val. Loss: 0.293 |  Val. Acc: 93.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4mCqAiyRw6V"
      },
      "source": [
        "accuracy on russian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qooDbdE1ZuO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81c0dc0f-be72-48f9-8e13-fd54b2bf8200"
      },
      "source": [
        "test_iterator = data.BucketIterator(ru_test, batch_size = 128, sort=False)\n",
        "\n",
        "test_loss, test_acc = evaluate(ru_model, test_iterator, criterion_ru, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.291 |  Test Acc: 93.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWhxPj6mRlqy"
      },
      "source": [
        "ru_uk_model = build_model(uk_train, uk_vec, TEXT, UD_TAGS, pretrained='russian_full.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k6nT3L-SX8i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2814e134-b0a1-4258-f318-ca454804f1ee"
      },
      "source": [
        "test_iterator = data.BucketIterator(uk_test, batch_size = 128, sort=False)\n",
        "\n",
        "test_loss, test_acc = evaluate(ru_uk_model, test_iterator, criterion_uk, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 6.325 |  Test Acc: 13.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ8KtYN4SjiR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1EBn3eySn1A"
      },
      "source": [
        "## Train Russian model on ukrainian, low-resource scenario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYWoHhU-S1pT"
      },
      "source": [
        "ru_uk_model = build_model(uk_train_low, uk_vec, TEXT, UD_TAGS, pretrained='russian_full.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIU7OI-2Tnz5"
      },
      "source": [
        "optimizer_ru_uk = optim.Adam(ru_uk_model.parameters(), lr=0.0007)\n",
        "\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "\n",
        "criterion_ru_uk = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrYSz3pMTGTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "6d4878dd-74c8-43e0-ae7a-215cd407fd38"
      },
      "source": [
        "train_model(ru_uk_model, \"ru+low_uk\", uk_train_low, uk_dev, optimizer_ru_uk, criterion_ru_uk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 3.605 | Train Acc: 25.37%\n",
            "\t Val. Loss: 1.719 |  Val. Acc: 49.78%\n",
            "Epoch: 02 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 1.582 | Train Acc: 51.99%\n",
            "\t Val. Loss: 1.254 |  Val. Acc: 59.09%\n",
            "Epoch: 03 | Epoch Time: 0m 17s\n",
            "\tTrain Loss: 1.190 | Train Acc: 62.17%\n",
            "\t Val. Loss: 1.040 |  Val. Acc: 68.19%\n",
            "Epoch: 04 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.954 | Train Acc: 71.13%\n",
            "\t Val. Loss: 0.895 |  Val. Acc: 72.95%\n",
            "Epoch: 05 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.791 | Train Acc: 76.58%\n",
            "\t Val. Loss: 0.800 |  Val. Acc: 75.74%\n",
            "Epoch: 06 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 0.686 | Train Acc: 79.65%\n",
            "\t Val. Loss: 0.739 |  Val. Acc: 77.00%\n",
            "Epoch: 07 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.619 | Train Acc: 81.25%\n",
            "\t Val. Loss: 0.709 |  Val. Acc: 77.54%\n",
            "Epoch: 08 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.575 | Train Acc: 82.49%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 77.98%\n",
            "Epoch: 09 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 0.544 | Train Acc: 82.97%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 78.10%\n",
            "Epoch: 10 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 0.513 | Train Acc: 83.91%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 78.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i396SxWV7y6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9927146-6ff8-4f37-ff27-2e82a767ab32"
      },
      "source": [
        "test_iterator = data.BucketIterator(uk_test, batch_size = 128, sort=False)\n",
        "\n",
        "test_loss, test_acc = evaluate(ru_uk_model, test_iterator, criterion_ru_uk, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.696 |  Test Acc: 77.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnWToeJlji_f"
      },
      "source": [
        "## Train Russian model on ukrainian, under-resource scenario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4A-_Ocgj8-g"
      },
      "source": [
        "ru_uk_model_f = build_model(uk_train, uk_vec, TEXT, UD_TAGS, pretrained='russian_full.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyV2vnFxj9MF"
      },
      "source": [
        "optimizer_ru_uk_f = optim.Adam(ru_uk_model_f.parameters(), lr=0.0007)\n",
        "\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "\n",
        "criterion_ru_uk_f = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVaSruiBkTFP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "52a19b5b-6028-4bd6-cec8-d28828106d8d"
      },
      "source": [
        "train_model(ru_uk_model_f, \"ru+f_uk\", uk_train, uk_dev, optimizer_ru_uk_f, criterion_ru_uk_f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 1.895 | Train Acc: 50.57%\n",
            "\t Val. Loss: 0.839 |  Val. Acc: 75.23%\n",
            "Epoch: 02 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.655 | Train Acc: 80.80%\n",
            "\t Val. Loss: 0.541 |  Val. Acc: 83.31%\n",
            "Epoch: 03 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.435 | Train Acc: 87.03%\n",
            "\t Val. Loss: 0.479 |  Val. Acc: 84.27%\n",
            "Epoch: 04 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.364 | Train Acc: 88.73%\n",
            "\t Val. Loss: 0.452 |  Val. Acc: 85.02%\n",
            "Epoch: 05 | Epoch Time: 0m 46s\n",
            "\tTrain Loss: 0.323 | Train Acc: 89.81%\n",
            "\t Val. Loss: 0.442 |  Val. Acc: 85.11%\n",
            "Epoch: 06 | Epoch Time: 0m 47s\n",
            "\tTrain Loss: 0.295 | Train Acc: 90.59%\n",
            "\t Val. Loss: 0.442 |  Val. Acc: 85.09%\n",
            "Epoch: 07 | Epoch Time: 0m 46s\n",
            "\tTrain Loss: 0.273 | Train Acc: 91.14%\n",
            "\t Val. Loss: 0.441 |  Val. Acc: 84.97%\n",
            "Epoch: 08 | Epoch Time: 1m 0s\n",
            "\tTrain Loss: 0.253 | Train Acc: 91.79%\n",
            "\t Val. Loss: 0.446 |  Val. Acc: 85.25%\n",
            "Epoch: 09 | Epoch Time: 0m 47s\n",
            "\tTrain Loss: 0.233 | Train Acc: 92.47%\n",
            "\t Val. Loss: 0.445 |  Val. Acc: 84.97%\n",
            "Epoch: 10 | Epoch Time: 0m 46s\n",
            "\tTrain Loss: 0.219 | Train Acc: 92.81%\n",
            "\t Val. Loss: 0.453 |  Val. Acc: 85.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2DlRL6P46HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3e28152-6843-4845-f907-aeec9552de90"
      },
      "source": [
        "test_iterator = data.BucketIterator(uk_test, batch_size = 128, sort=False)\n",
        "\n",
        "test_loss, test_acc = evaluate(ru_uk_model_f, test_iterator, criterion_ru_uk_f, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.467 |  Test Acc: 84.53%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxvkvdIZTbSR"
      },
      "source": [
        "!cp ru* /content/drive/My\\ Drive/diploma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZaurg_WU5zR"
      },
      "source": [
        "!cp uk* /content/drive/My\\ Drive/diploma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyaRWxesU-_W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrj-pLAqmAEe"
      },
      "source": [
        "def draw_heatmap(model, iterator, criterion, tag_pad_idx):\n",
        "    real = []\n",
        "    predicted = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            tags = batch.udtags\n",
        "            predictions = model(text)\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "            real.append(tags)\n",
        "            predicted.append(predictions)\n",
        "    return real[0], predicted[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRlxSoVbucjX"
      },
      "source": [
        "m = '/content/drive/My Drive/diploma/ru+low_uk.pt'\n",
        "m = build_model(uk_train_low, uk_vec, TEXT, UD_TAGS, pretrained=m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUCGgeDnu0DQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56008338-6afd-4221-eeb5-05e123b45591"
      },
      "source": [
        "tir = data.BucketIterator(uk_test, batch_size = 128, sort=False)\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "crit= nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "test_loss, test_acc = evaluate(m, tir, crit, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.324 |  Test Acc: 60.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwmWyoV6vV0h"
      },
      "source": [
        "a, b = draw_heatmap(m, tir, crit, TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TepyErp_xl6e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}